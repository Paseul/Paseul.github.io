<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-01-16T10:37:13+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Paseul’s Devlog</title><subtitle>C#, Python, Docker, Kubernetes, Deep learning, Reinforcement learning</subtitle><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><entry><title type="html">초고해상도 상성적 적대 신경망</title><link href="http://localhost:4000/srgan/" rel="alternate" type="text/html" title="초고해상도 상성적 적대 신경망" /><published>2020-01-09T00:00:00+09:00</published><updated>2020-01-09T00:00:00+09:00</updated><id>http://localhost:4000/srgan</id><content type="html" xml:base="http://localhost:4000/srgan/">&lt;h1 id=&quot;srgan&quot;&gt;SRGAN&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1609.04802.pdf&quot;&gt;Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;SRGAN(super-resolution generative adversarial network)은 GAN의 일종으로, 저해상도 이미지의 세부사항을 다듬고 품질을 높여서 초 고해상도 이미지로 생성해 낸다&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;생성기:&lt;/strong&gt; 생성기 신경망은 64x64x3 차원으로 된 저해상도 이미지 한개를 취해서 일련의 합성곱 및 상향 표본 추출 계층들을 거쳐 256x256x3 모양으로 된 초 고해상도 이미지 한개를 생성해 낸다&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;판별기:&lt;/strong&gt; 판별기 신경망은 고해상도 이미지 한 개를 취해 해당 이미지가 진짜인지(진짜 데이터 표본들 중에서 나온 것인지) 아니면 가짜인지(생성기가 생성해 낸 이미지인지)를 식별해 낸다&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;srgan의-아키텍처&quot;&gt;SRGAN의 아키텍처&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/SRGAN_architecture.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;생성기 신경망 아키텍처&lt;/strong&gt;
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Input Layer of the generator network
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;input_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Add the pre-residual block
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;gen1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Add 16 residual blocks
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;residual_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;residual_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Add the post-residual block
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;gen2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;gen2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BatchNormalization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Take the sum of the output from the pre-residual block(gen1) and the post-residual block(gen2)
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;gen3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gen1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Add an upsampling block
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;gen4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UpSampling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;gen4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;gen4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Add another upsampling block
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;gen5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;UpSampling2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;gen5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;gen5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'relu'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Output convolution layer
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;gen6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strides&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'same'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'tanh'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

  &lt;span class=&quot;c1&quot;&gt;# Keras model
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'generator'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author></entry><entry><title type="html">머신러닝 라이브러리</title><link href="http://localhost:4000/deeplearning/ml-library/" rel="alternate" type="text/html" title="머신러닝 라이브러리" /><published>2020-01-03T00:00:00+09:00</published><updated>2020-01-03T00:00:00+09:00</updated><id>http://localhost:4000/deeplearning/ml-library</id><content type="html" xml:base="http://localhost:4000/deeplearning/ml-library/">&lt;h2 id=&quot;딥러닝-어플리케이션&quot;&gt;딥러닝 어플리케이션&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;지도학습:&lt;/strong&gt;&lt;/span&gt; 사전에 주어진 정답 데이터를 바탕으로 학습하는 머신러닝 방법, 레이블을 추정하는 분류 문제와 연속 값을 추정하는 외귀 문제 등이 있다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;전이학습:&lt;/strong&gt; &lt;/span&gt;어떤 문제를 풀기 위해서 학습된 모델을 이용해서 다른 문제를 풀 모델을 구축하는 방법의 일종이다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;원샷학습(one-shot lerning):&lt;/strong&gt;&lt;/span&gt; 1개 또는 아주 적은 샘플만을 가지고 학습하는 머신러닝 방법의 하나&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;GAN:&lt;/strong&gt;&lt;/span&gt; Generative Adversarial Network(적대적 생성 네트워크)의 약어. 훈련 데이터를 학습하고, 그 데이터와 닮은 새로운 데이터를 생성하는 생성모델의 일종이다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;DCGAN:&lt;/strong&gt;&lt;/span&gt; Deep Convolutional GAN(심층 합성곱 적대적 생성 네트워크)의 약어. GAN 중에서도 특히 여러 층의 합성곱 네트워크를 이용하는 것을 가리킨다. DCGAN으로 고해상도의 이미지 생성이 가능해졌다&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;텐서플로의-특징&quot;&gt;텐서플로의 특징&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;텐서플로는 구글(Google)이 중심으로 개발하고 있는 OSS(오픈 소스 소프트웨어)의 머신러닝 라이브러리&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;방향성 비순환 그래프(DAG: Directed acyclic graph) 기반:&lt;/strong&gt;&lt;/span&gt; 텐서끼리의 연산(덧셈, 곱셈)결과도 텐서가 되는 성질이 있기 때문에 복잡한 연산도 서로 화살표로 연결된 루프가 없는 네트워크로 표현할 수 있다&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;다양한 환경에서 동작:&lt;/strong&gt;&lt;/span&gt; 기본적으로 CPU에서나 GPU에서도 같은 코드로 동작한다. 또, 파이써을 사용해서 구축한 그래프를 저장한 다음 다른 언어에서 호출할 수도 있다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;분산 처리:&lt;/strong&gt;&lt;/span&gt; 일반저으로 분산 처리를 잘 다루려면 매우 높은 기술력이 필요하지만, 텐서플로를 이용하면 간단히 기술할 수 있다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;텐서 보드:&lt;/strong&gt;&lt;/span&gt; 텐서 보드를 통해 손실함수의 경과나 중간층의 모습,  추출한 특징량의 가시화와 같은 기능이 있다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;다양한 수준의 API와 에코시스템:&lt;/strong&gt;&lt;/span&gt; 저수준 API에서부터 고수준 API까지 폭넓게 커버하며, 커뮤니티가 매우 큰 것 또한 장점이다
*케라스의 특징: 간단한 모듈 구성, 구축한 모델이 사이킷런(scikit-learn)과 비슷한 인터페이스를 거쳐서 학습과 평가를 실행할 수 있다 *&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;딥러닝-라이브러리-동향&quot;&gt;딥러닝 라이브러리 동향&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;Define and Run:&lt;/strong&gt;&lt;/span&gt; 텐서플로처럼 먼저 계산그래프를 정의하고, 한꺼번에 처리하는 것을 말한다. 일반 프로그래밍 언어와 패러다임이 다르기 때문에 &lt;em&gt;학습 비용이 조금 높다&lt;/em&gt;는 단점이 있지만, 고속화가 쉽다는 장점이 있다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;Define by Run:&lt;/strong&gt;&lt;/span&gt; 사전에 계산 그래프를 정의해 두지 않고, 그래프의 정의와 처리를 동시에 하는것. 처리 결과에 따라 계산 그래프를 동적으로 바꿀 수 있어서 &lt;em&gt;구현을 단순하게 할 수 있다&lt;/em&gt;는 장점과 &lt;em&gt;디버깅 시 오류 부분을 파악하기 쉽다&lt;/em&gt;는 장점이 있다 &lt;em&gt;텐서플로도 r1.5에서 부터 Define by Run으로 기술할 수 있게 되고 있다&lt;/em&gt;&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;Chainer:&lt;/strong&gt;&lt;/span&gt; Define by Run을 제창한 라이브러리로 ChanerMN를 이용하여 분산 처리를 지원&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;Pytorch:&lt;/strong&gt;&lt;/span&gt; 페이스북이 중심이 되어 개발되었고, 사용하기 쉬워서 매우 인기있는 라이브러리가 되었다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;Gluon:&lt;/strong&gt;&lt;/span&gt; AWS가 지원을 표명한 MXNet의 래퍼 라이브러리다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;ONNX:&lt;/strong&gt;&lt;/span&gt; 딥러닝 모델을 표현하기 위한 공통포맷이다. 아파치 MXNet, Caffe2, CNTK, Pytorch와 같은 딥러닝 라이브러리 간의 상호운용을 가능하게 한다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;콜라보레이터리(Colabratory):&lt;/strong&gt;&lt;/span&gt; 12시간의 제약은 있지만, GPU를 이용해서 딥러닝 모델을 구축하거나 구글 드라이브에서 코드를 공유할 수 있게 됐다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;AWS SageMaker:&lt;/strong&gt;&lt;/span&gt; AWS에서 제공하는 풀 관리 서비스로서 주피터 노프북을 사용한 모델 구축부터 학습, 모델의 호스팅까지 일련의 단계를 매우 쉽게 실행할 수 있다&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;출처:  실전! 딥러닝, “위키북스”&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><category term="DeepLearning" /></entry><entry><title type="html">5G 국제 표준의 이해</title><link href="http://localhost:4000/networks/5g-nr-standards/" rel="alternate" type="text/html" title="5G 국제 표준의 이해" /><published>2019-12-27T00:00:00+09:00</published><updated>2019-12-27T00:00:00+09:00</updated><id>http://localhost:4000/networks/5g-nr-standards</id><content type="html" xml:base="http://localhost:4000/networks/5g-nr-standards/">&lt;p&gt;본 포스팅은 삼성에서 제공한 &lt;a href=&quot;https://images.samsung.com/is/content/samsung/p5/global/business/networks/insights/white-paper/who-and-how_making-5g-nr-standards/who-and-how_making-5g-nr-standards_KR.pdf&quot;&gt;5G 국제 표준의 이해&lt;/a&gt;를 요약 정리한 포스팅 입니다&lt;/p&gt;
&lt;h1 id=&quot;5g-nrnew-radio-표준&quot;&gt;5G NR(New Radio) 표준&lt;/h1&gt;
&lt;h2 id=&quot;표준의-정의&quot;&gt;&lt;strong&gt;표준의 정의&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;표준(Standardization)을 통하여 특정 국가나 사업자에게만 특화된 제품이 아니라 전세계에서 통용되는 제품을 생산할 수 있게 된다.
과거에는 국가별, 제조사별, 표준화 단체별로 제품을 개발하여 시장을 많이 점유한 기술이 사실상(De-facto) 국제표준이 되기도 했으나 &lt;span style=&quot;color:#F9E79F&quot;&gt;최근에는 이러한 규격을 표준화하여 국제적으로 합의된 국제 표준을 사용하고 있다.&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;국제 표준을 통해&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;R&amp;amp;D 비용 절감&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소비자는&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;통신기능 주체간에 정보교환 및 신호 처리가 가능&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;제조사는 대량생산, 중복투자 방지, 기술이전, 가능&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;제조사간의 경쟁을 통해 가성비 높은 제품을 확보&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;Generation 구분:&lt;/strong&gt;&lt;/span&gt;  각 세대를 구분 짓는 것은 새로운 서비스가 아니라, 그런 서비스를 가능하게 한 &lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;‘기술적 혁신’&lt;/strong&gt;&lt;/span&gt; 새로운 이동통신 기술 혁신들은 바로 각 세대의 &lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;“표준”&lt;/strong&gt;에 의해 정의되어 왔다.&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;5g-표준&quot;&gt;&lt;strong&gt;5G 표준&lt;/strong&gt;&lt;/h2&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/Networks/ITU-3GPP_relationship.PNG&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;p&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;ITU(국제 전기 통신 연합, International Telecommunication Union)&lt;/strong&gt;&lt;/span&gt; 에서 비전 및 목표를 제시하고  &lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;국제 표준화 단체(3GPP)&lt;/strong&gt;&lt;/span&gt; 에서 기술 표준 개발
&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;3GPP&lt;/strong&gt;&lt;/span&gt;는 전세계 이동통신 사업자, 장비 제조사, 단말 제조사, 칩 제조사 및 세계 각국의 표준화 단체와 연구기관 등 약 500여개 업체가 참여하는 최대 국제 이동통신 표준화 단체&lt;br /&gt;&lt;br /&gt;
&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;5G 표준의 특징&lt;/strong&gt;&lt;/span&gt;&lt;br /&gt;
1) &lt;span style=&quot;color:#F9E79F&quot;&gt;초 광대역 서비스 (eMBB: enhanced Mobile Broadband):&lt;/span&gt; 사용자당 100Mbps에서 최대 20Gbps까지 훨씬 빠른 데이터 전송속도 제공을 목표&lt;br /&gt;
2) &lt;span style=&quot;color:#F9E79F&quot;&gt;고신뢰/초저지연 통신 (URLLC: Ultra Reliable &amp;amp; Low Latency Communications):&lt;/span&gt; 기존 수십 밀리 세컨드 (1ms = 1/1000 초) 걸리던 지연 시간을 1ms 수준으로 최소화하는 것을 목표&lt;br /&gt;
3) &lt;span style=&quot;color:#F9E79F&quot;&gt;대량연결 (mMTC: Machine-Type Communications):&lt;/span&gt; 1 km2 면적 당1백만개의 연결(connection)을 지원하는 것을 목표&lt;br /&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/Networks/4Gvs5G.PNG&quot; width=&quot;70%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;em&gt;4G LTE도 초기 상용화 시점(2010년 경) 당시 최대속도가 75Mbps였고 2018년에야 목표성능 1Gbps 상용이 가능 했고 5G도 마찬가지일 것으로 예상된다&lt;/em&gt;&lt;/span&gt;&lt;br /&gt;
&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;em&gt;4G의 주파수 대역은  6GHz 이하(Below 6GHz)였지만 28GHz와 39GHz 등 밀리미터파(mmWave)로 불리는 초고주파 대역(Above 6GHz)까지 함께 사용하게 된다&lt;/em&gt;&lt;/span&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;빔 포밍 기술:&lt;/strong&gt;&lt;/span&gt; 많은 수의 안테나에 실리는 신호를 각각 정밀하게 제어하여 특정 방향으로 에너지를 집중시키거나 또는 반대로 특정 방향으로는 에너지가 가지 않도록 조절이 가능한 기술. 전파의 에너지를 집중시켜 거리를 늘리고 빔(Beam)간에는 간섭을 최소화 시킬 수 있다. 이렇게 예리한 빔을 계속 정확하게 추적(tracking) 해야 하는 것이 기술적 관건이 된다.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/Networks/Beamforming.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;Massive MIMO:&lt;/strong&gt;&lt;/span&gt; 수 많은 안테나 배열(Massive Antenna Array)을 활용하여 같은 무선 자원을 여러명이 동시에 사용하는 기술. 4G에서의 MIMO기술은 1차원(1D) 안테나 배열을 사용하였기 때문에 자유도(degree of freedom)가 낮아 수평방향(horizontal)사용자만 구분 했지만 5G에서는 수십개 이상의 안테나를 2차원(2D)으로 배치해 수직-수평(horizontal &amp;amp; vertical)방향 모두 사용자를 구분할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/Networks/MassiveMIMO.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;Network Slicing:&lt;/strong&gt;&lt;/span&gt; 4G에서는 Voice와 Data 서비스로 구분해서 Voice에 대해서만 별도의 Qos(Quality-of-Service)를 제공했지만, 5G에서는 네트워크 슬라이싱을 통해 각각의 Data 서비스들도 독립적인 네트워크 자원 할당이 가능하고 따라서 각 서비스별로 다른 서비스의 영향을 받지 않으면서 품질을 보장할 수 있다. &lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;em&gt;특히, 시간지연에 민감한 서비스(Mission Critical Service)들의 품질을 보장할수 있게 되어 이동통신 사업자는 특화 서비스에 대한 별도의 과금체계도 도입할 수 있다.&lt;/em&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/Networks/NetworkSlicing.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;NSA와 SA:&lt;/strong&gt;&lt;/span&gt; NAS(Non-Standalone)는 초기 상용망에 구현괄 것으로 예상되는 구조로, 단말의 이동성(mobility) 관리 등을 제어하는 제어 플레인(control plane)의 동작은 4G LTE 망을 활용하면서 사용자 플레인(User plane/Data plane)에 해당하는 데이터 트래픽은 5G 망으로 주고 받는다. SA(Standalone) 구조는 제어 채널이나 데이터 채널 모두 5G의 자체구조를 사용하는 구조이다.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/Networks/NSA-SA.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;표준의 Release 개념:&lt;/strong&gt;&lt;/span&gt; &lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;Release는 3GPP의 시간 스케쥴이다.&lt;/strong&gt;&lt;/span&gt; 이동통신 국제 표준은 단기간에 1회성으로 정해지는 것이 아니며 장기간에 걸쳐 수 차례 업그레이드 된다. 다음 세대가 나오더라도 수년정도는 이전 세대 기술이 계속 보완하여 발표(Release) 한다.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/Networks/Release.PNG&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><category term="Networks" /><category term="5G NR" /><category term="ITU" /><category term="3GPP" /><category term="빔 포밍" /><category term="Massive MIMO" /><category term="Network Slicing" /><category term="NSA" /><category term="SA" /></entry><entry><title type="html">신경망 아키텍처</title><link href="http://localhost:4000/deeplearning/neural-network-architecture/" rel="alternate" type="text/html" title="신경망 아키텍처" /><published>2019-12-09T00:00:00+09:00</published><updated>2019-12-09T00:00:00+09:00</updated><id>http://localhost:4000/deeplearning/neural-network-architecture</id><content type="html" xml:base="http://localhost:4000/deeplearning/neural-network-architecture/">&lt;h1 id=&quot;신경망-아키텍처&quot;&gt;신경망 아키텍처&lt;/h1&gt;
&lt;h2 id=&quot;mlp&quot;&gt;MLP&lt;/h2&gt;
&lt;p&gt;다층 퍼셉트론(multilayer perceptron, MLP)은 신경망 아키텍처의 가장 기본적인 형태로서 신경 유닛은 층층이 배열되고 인접한 네트워크 층은 전체가 모두 연결된다&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://missinglink.ai/wp-content/uploads/2018/11/multilayer-perceptron.png&quot; alt=&quot;출처: https://missinglink.ai/guides/neural-network-concepts/perceptrons-and-multi-layer-perceptrons-the-artificial-neuron-at-the-core-of-deep-learning/&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;autoencoder&quot;&gt;Autoencoder&lt;/h2&gt;
&lt;p&gt;오토인코더 신경망(Autoencoder)의 목표값은 입력값과 동일하게 설정된다. 은닉층당 유닛 수가 점진적으로 증가하기 전에 특정 시점까지 점진적으로 감소하고, 최종 층의 차원은 입력 차원과 동일하다. 은닉층의 앞쪽 절반을 인코더(encoder) 뒤쪽 절반을 디코더(decoder)라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Autoencoder_structure.png/350px-Autoencoder_structure.png&quot; alt=&quot;출처: https://en.wikipedia.org/wiki/Autoencoder&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;vaes&quot;&gt;VAEs&lt;/h2&gt;
&lt;p&gt;변분 오토인코더(variational autoencoders, VAEs)의 디코더 부분은 오토 인코더와 동일하고 인코더 부분에서 확률층(noise)를 추가하여 여러 샘플을 얻어서 최대 가능도로 손실함수를 도출한다&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/max/1664/1*eRcdr8gczweQHk--1pZF9A@2x.png&quot; alt=&quot;출처: https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;gan&quot;&gt;GAN&lt;/h2&gt;
&lt;p&gt;적대적 신경망(Generatice Adversarial Networks, GAN)에는 생성기 신경망과 판별기 신경망이 있다. 생성기 네트워크는 임의의 소음을 입력받아 데이터 샘플을 생성하려고 시도한다. 판별기 네트워크는 생성된 데이터를 실제 데이터와 비교하고 생성된 데이터가 가짜인지 아닌지에 대한 이진 분류 문제를 시그모이드 출력 활성화를 사용해 해결한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://developers.google.com/machine-learning/gan/images/gan_diagram_discriminator.svg&quot; alt=&quot;출처: https://developers.google.com/machine-learning/gan/discriminator&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;lenet&quot;&gt;LeNet&lt;/h2&gt;
&lt;p&gt;1998년에 설계한 7단계 합성곱 네트워크로, 숫자 분류에 사용된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://notebooks.azure.com/rodolfoferro/libraries/KerasMNIST/raw/LeNet-5.png&quot; alt=&quot;출처: https://notebooks.azure.com/rodolfoferro/projects/KerasMNIST/html/MNIST%20-%20CNN%20Model.ipynb&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;alexnet&quot;&gt;AlexNet&lt;/h2&gt;
&lt;p&gt;2012년 ILSVRC우승팀의 아키텍처. LeNet과 매우 유사한 아키텍처를 가지고 있지만, 층당 필터가 더 많고 깊다. 또한 항상 대체된 합성곱 풀링 대신 스택 합성곱을 사용한다. 작은 합성곱의 스택은 합성곱층의 하나로 된 커다란 수용 영역보다 낫다. 더 많은 비선형성과 더 적은 파라미터를 도입하기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://openresearch.ai/uploads/default/original/1X/b25dce7cb47b0a80b3631d10476a630df4b1f2ff.jpg&quot; alt=&quot;출처: Alexnet 논문&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;zfnet&quot;&gt;ZFNet&lt;/h2&gt;
&lt;p&gt;2013년 ILSVRC 우승팀의 아키텍처. AlexNet을 향상시키기 위해 아키텍처 하이퍼 파라미터를 조정했는데, 특히 중간 합성곱층의 크기를 확장하고 첫 번째 층의 스트라이드와 필터 크기를 작게 함으로써 11x11 스트라이드 4인 AlexNet이 7x7 스트라이드 2인 ZFNet으로 변경됐다. 이렇게 시도한 이유는 첫 번째 합성곱층의 필터 크기가 작으면 많은 원본 픽셀 정보를 유지하는 데 도움이 되기 때문이다. 또한 AlexNet은 1,500만 개의 이미지에 대한 훈련을 받았지만, ZFNet은 130만 개의 이미지에 대해서만 훈련을 받았다&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;amp;fname=http%3A%2F%2Fcfile24.uf.tistory.com%2Fimage%2F9937CC415AED57D7160153&quot; alt=&quot;출처: ZFNet 논문&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;googlenet&quot;&gt;GoogLeNet&lt;/h2&gt;
&lt;p&gt;2014년 ILSVRC 우승팀의 아키텍처. GoogLeNet은 CNN을 사용해 인셉션층(Inception layer)이라는 새로운 아키텍처의 구성요소를 도입했다. 인셉션 층은 더 큰 합성곱을 사용하고 더 작은 정보의 이미지에도 정밀한 해상도를 유지할 수 있기 때문에 적용되었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/GoogLeNet.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;vgg&quot;&gt;VGG&lt;/h2&gt;
&lt;p&gt;2014년 ILSVRC 준우승팀의 아키텍처. VGG 네트워크는 단순함이 그 특징인데, 3x3 합성곱층만 사용해 쌓아올렸다. 부피를 줄이는 것은 Max Pooling으로 처리된다. 마지막에는 4,096개의 노드가 있는 두 개의 전체가 연결된 층에 소프트맥스 층이 이어진다. 입력에 대한 전처리는 훈련 세트에서 계산된 평균 RGB 값을 각 픽셀에서 빼는 것이다. 풀링은 일부 합성곱층을 따르는 Max Pooling에 의해 이루어 진다. 모든 합성곱층 다음에 Max Pooling이 이어지는 것은 아니다. Max Pooling은 스트라이드가 2인 2x2 픽셀 윈도에서 이루어진다. ReLU 활성화는 각각의 은닉층에서 사용된다. 필터의 수는 대부분 VGG 변형에서 깊이에 따라 증가한다. 16층은 VGG-16, 19층은 VGG-19.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/VGG16.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;resnet&quot;&gt;ResNet&lt;/h2&gt;
&lt;p&gt;2015년 ILSVRC 우승팀의 아키텍처. 잔차 신경망(Residual Neural Network: ResNet)은 연결 건너뛰기와 배치 정규화를 사용하는 새로운 CNN 아키텍처로서 이를 통해 VGG 네트워크보다 복잡성이 낮은데도 152층의 신경망을 훈련할 수 있었다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/ResNet.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;capsnet&quot;&gt;CapsNet&lt;/h2&gt;
&lt;p&gt;캡슐 네트워크(CapsNet)는 CNN의 스칼라 출력 함수 감지기를 벡터 출력 캡슐로 대체한다. 또 라우팅별로 Max Pooling을 사용한다&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/CapsNet.jpg&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;rnn&quot;&gt;RNN&lt;/h2&gt;
&lt;p&gt;순환 신경망(recurrent neural Network, RNN)은 시퀀스를 처리하는 데 특화돼 있다. 예를 들어, 주어진 최근 시퀀스로부터 다음 시퀀스에 있는 용어를 예측하거나 한 언어에서 다른 언어로 단어의 시퀀스를 번역하려는 경우, 시퀀스 모델링을 할 필요가 있다. RNN은 아키텍처에 피드백 루프가 있다는 점에서 전방 전달 네트워크와 구별된다. 종종 RNN에는 메모리가 있다고 한다. RNN은 시간이 지남에 따라 순서대로 이전 내용을 잃기 시작한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/RNN.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;lstm&quot;&gt;LSTM&lt;/h2&gt;
&lt;p&gt;LSTM은 일반적으로 입력, 출력 및 망각 게이트를 포함해 3개 또는 4개의 게이트로 구성된다. 입력 게이트는 일반적으로 들어오는 신호 또는 입력을 수용하거나 거부해 메모리 셀 상태를 변경한다. 출력 게이트는 일반적으로 필요에 따라 다른 뉴런에 값을 전달한다. 망각 게이트는 메모리 셀의 자기 반복 연결을 제어해 필요에 따라 이전 상태를 기억하거나 잊어버린다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/LSTM.png&quot; width=&quot;80%&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;nmt&quot;&gt;NMT&lt;/h2&gt;
&lt;p&gt;신경망 기반 기계 번역(Neural Machine Translation, NMT) 시스템은 일반적으로 인코더와 디코더 두 모듈로 구성된다. 먼저 인코더로 소스 문장을 읽고 생각 벡터를 만든다. 이 벡터는 문장의 의미를 나타내는 숫자의 시퀀스로 구성된다. 디코더는 문장 벡터를 처리해 다른 타깃 언어로 번역을 출력한다. 이를 인코더-디코더 아키텍처라고 한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/NMT.jpg&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;h2 id=&quot;gru&quot;&gt;GRU&lt;/h2&gt;
&lt;p&gt;게이트 순환 유닛(Gated Recurrent Units, GRU)은 LSTM과 관련이 있다. 둘 다 게이트 정보의 다른 방법을 사용해 기울기 소멸 문제를 방지하고 장기 메모리에 저장한다. GRU에는 두 개의 게이트가 있는데, 리셋 게이트 r과 업데이트 게이트 z다 . 리셋 게이트는 새 입력을 어떻게 이전의 은닉상태와 결합할 것인지 결정하고 업데이트 게이트는 유지할 이전 상태 정보의 양을 정의한다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/GRU.png&quot; width=&quot;50%&quot; /&gt;&lt;/center&gt;

&lt;blockquote&gt;
  &lt;p&gt;출처: 딥러닝 전이학습, “위키북스”&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><category term="Deep Learning" /></entry><entry><title type="html">우분투 쿠버네티스 설치</title><link href="http://localhost:4000/ubuntu/ubuntu_kubernetes_install/" rel="alternate" type="text/html" title="우분투 쿠버네티스 설치" /><published>2019-11-28T00:00:00+09:00</published><updated>2019-11-28T00:00:00+09:00</updated><id>http://localhost:4000/ubuntu/ubuntu_kubernetes_install</id><content type="html" xml:base="http://localhost:4000/ubuntu/ubuntu_kubernetes_install/">&lt;h1 id=&quot;우분투-환경에서-쿠버네티스-설치하기dashboard-까지&quot;&gt;우분투 환경에서 쿠버네티스 설치하기(dashboard 까지)&lt;/h1&gt;
&lt;h2 id=&quot;개요&quot;&gt;개요&lt;/h2&gt;
&lt;p&gt;쿠버네티스를 설치하는 방법은 OS나 사용하는 플랫폼에 따라서 달라진다. &lt;br /&gt;
본 포스팅에서는 우분투 환경에서 쿠버네티스를 설치하고 추가적으로 쿠버네티스 대시보드까지 설치해 보도록 하겠다. &lt;br /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;실행 환경: Ubuntu 18.04(LTS)&lt;br /&gt;
도커 버전: 19.03&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;쿠버네티스의 &lt;a href=&quot;https://kubernetes.io/ko/docs/setup/&quot;&gt;한글 문서&lt;/a&gt; 에 보면 공식적으로 지원하는 커뮤니티와 생태계를 확인할 수 있다. &lt;br /&gt;
&lt;span style=&quot;color:#F9E79F&quot;&gt;윈도우&lt;/span&gt;의 경우에는 &lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;Docker Desktop&lt;/strong&gt;&lt;/span&gt; 로 선택지가 정해져있지만 Linux의 경우는 MicroK8s, k3s, Ubuntu on LXD등 다양한 생태계를 공식적으로 지원하기 때문에 상황에 맞는 생태계를 선택하면 될 것 같다.&lt;br /&gt;
본인은 이중에서 &lt;a href=&quot;https://ubuntu.com/kubernetes/install#multi-node&quot;&gt;ubuntu.com&lt;/a&gt; 에 나온 &lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;MicroK8s&lt;/strong&gt;&lt;/span&gt;를 사용하여 설치 해보았다 &lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;microk8s-설치-절차&quot;&gt;microk8s 설치 절차&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:#F1948A&quot;&gt;&lt;strong&gt;1. Install the microk8s snap&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo snap install microk8s --classic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;span style=&quot;color:#F1948A&quot;&gt;&lt;strong&gt;2.  Check the status&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo microk8s.status --wait-ready
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;span style=&quot;color:#F1948A&quot;&gt;&lt;strong&gt;3. Turn on standard services&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo microk8s.enable dns dashboard registry
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;MicroK8s 명령을 통해 kubectl 명령을 다음과 같이 수행&lt;/span&gt;할 수 있다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ microk8s.kubectl
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;kubernetes-dashboard-설치-절차&quot;&gt;kubernetes dashboard 설치 절차&lt;/h2&gt;
&lt;p&gt;이제 kubernetes dashboad를 설치하러 가보자
대시보드 UI는 기본으로 배포되지 않기 때문에 &lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;a href=&quot;https://kubernetes.io/ko/docs/tasks/access-application-cluster/web-ui-dashboard/&quot;&gt;쿠버네티스 대시보드 문서&lt;/a&gt;&lt;/span&gt; 를 참조하여 설치해 보도록 하겠다&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#F1948A&quot;&gt;&lt;strong&gt;1. Install kubenetes dashboard&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ microk8s.kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0-beta4/aio/deploy/recommended.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;설치가 종료되면 접속을 위한 토큰을 아래 명령을 통해 미리 생성해 둔다&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#F1948A&quot;&gt;&lt;strong&gt;2. Bearer Token&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ microk8s.kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '{print $1}')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;이 명령을 입력하면 아래와 같이 토큰이 나온다 &lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Name:         admin-user-token-v57nw
Namespace:    kubernetes-dashboard
Labels:       &amp;lt;none&amp;gt;
Annotations:  kubernetes.io/service-account.name: admin-user
              kubernetes.io/service-account.uid: 0303243c-4040-4a58-8a47-849ee9ba79c1

Type:  kubernetes.io/service-account-token

Data
====
ca.crt:     1066 bytes
namespace:  20 bytes
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXY1N253Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiIwMzAzMjQzYy00MDQwLTRhNTgtOGE0Ny04NDllZTliYTc5YzEiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.Z2JrQlitASVwWbc-s6deLRFVk5DWD3P_vjUFXsqVSY10pbjFLG4njoZwh8p3tLxnX_VBsr7_6bwxhWSYChp9hwxznemD5x5HLtjb16kI9Z7yFWLtohzkTwuFbqmQaMoget_nYcQBUC5fDmBHRfFvNKePh_vSSb2h_aYXa8GV5AcfPQpY7r461itme1EXHQJqv-SN-zUnguDguCTjD80pFZ_CmnSE1z9QdMHPB8hoB4V68gtswR1VLa6mSYdgPwCHauuOobojALSaMc3RH7MmFUumAgguhqAkX3Omqd3rJbYOMRuMjhANqd08piDC3aIabINX6gP5-Tuuw2svnV6NYQ
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;토큰이 생성되었다면 프록시 명령을 통해 대시보드를 사용할 수 있다&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#F1948A&quot;&gt;&lt;strong&gt;3. kubectl proxy&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ microk8s.kubectl proxy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 &lt;a href=&quot;http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/&quot;&gt;http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/&lt;/a&gt; 에 접속하여 token을 입력하면&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://d33wubrfki0l68.cloudfront.net/5f56e7ac82f10f46e70403a246c2b93efcf8b5b3/1c09f/images/docs/ui-dashboard-zerostate.png&quot; alt=&quot;웰컴 뷰&quot; /&gt;&lt;/p&gt;

&lt;p&gt;짜잔~! 대시보드를 확인할 수 있다&lt;/p&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><category term="Ubuntu" /><category term="Docker" /><category term="Kubernetes" /><category term="Dashboard" /></entry><entry><title type="html">생성적 적대 신경망 소개</title><link href="http://localhost:4000/deeplearning/gan_introduction/" rel="alternate" type="text/html" title="생성적 적대 신경망 소개" /><published>2019-11-27T00:00:00+09:00</published><updated>2019-11-27T00:00:00+09:00</updated><id>http://localhost:4000/deeplearning/gan_introduction</id><content type="html" xml:base="http://localhost:4000/deeplearning/gan_introduction/">&lt;h1 id=&quot;생성적-적대-신경망generative-adversarial-networks-gan&quot;&gt;생성적 적대 신경망(generative adversarial networks, GAN)&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;2014년 Ian Goodfellow 등의 &lt;a href=&quot;https://arxiv.org/pdf/1406.2661&quot;&gt;논문&lt;/a&gt;에서 처음 소개된 심층 신경망 아키텍처&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;gan-이란-무엇인가&quot;&gt;GAN 이란 무엇인가?&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;GAN은 생성기 신경망과 판별기 신경망이라고 하는 두 가지 신경망으로 구성된 심층 신경망 아키텍처&lt;/strong&gt;&lt;/span&gt;이다. 예를들어 생성기 신경망은 위조 지폐를 생성하여 판별기 신경망을 속이는 것을 목표로 하고, 판별기 신경망은 위조지폐를 찾아내는 것을 목표로 한다. 위조지폐가 정교해지면 판별성능이 떨어지고  반복학습을 통해 판별기가  발전하고, 판별기가 위조지폐를 잘 찾아내면 생성기가 반복학습을 통해 발전하는 원리로 적대적으로 경쟁하며 발전시킨다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/DeepLearning/GAN.png&quot; width=&quot;60%&quot; /&gt;&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;
&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;생성기 신경망(generator network):&lt;/strong&gt;&lt;/span&gt; 기존 데이터를 사용해 신규 데이터를 생성해 낸다&lt;br /&gt;(예: 이미지, 비디오, 오디오 또는 텍스트 등)&lt;br /&gt;
&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;판별기 신경망(discriminator network):&lt;/strong&gt;&lt;/span&gt; 진짜 데이터와 신규 데이터를 구분하는 신경망으로 다중 분류나 이진 분류 모두 가능하다&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GAN 훈련 과정&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;생성기가 진짜 데이터를 통해 가짜 데이터를 생성한다&lt;/li&gt;
  &lt;li&gt;판별기는 가짜 데이터를 구분해 낸다&lt;/li&gt;
  &lt;li&gt;생성기는 이와 같은 과정을 반복하면서 진짜에 가까운 데이터를 생성하고, 판별기는 기준(criterion)을 조정하면서 구분한다&lt;/li&gt;
  &lt;li&gt;생성기와 판별기는 각 반복과정에서 성공적인 변경사항을 피드백 하면서 훈련한다&lt;/li&gt;
  &lt;li&gt;궁극적으로, 판별기는 진짜 데이터와 가짜 데이터를 구분하지 못하게 생성기를 훈련시키게 된다&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;gan의-아키텍처&quot;&gt;GAN의 아키텍처&lt;/h2&gt;
&lt;p&gt;생성기와 판별기 모두 &lt;span style=&quot;color:#AED6F1&quot;&gt;&lt;strong&gt;인공 신경망(artificial neural network, ANN), 합성곱 신경망(convolutional neural network, CNN), 재귀 신경망(recurrent neural network, RNN) 또는 장단기 기억 신경망(long short term memory, LSTM)&lt;/strong&gt;&lt;/span&gt; 을 신경망으로 사용할 수 있으며, 판별기 끝부분에 있는 분류기가 완전 연결형태여야 한다&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;생성기 아키텍처 예&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;계층#&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;계층 이름&lt;/th&gt;
      &lt;th&gt;구성&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Input layer&lt;/td&gt;
      &lt;td&gt;input_shape=(batch_size, 100), output_shape=(batch_size, 100)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dense layer&lt;/td&gt;
      &lt;td&gt;neurons=500, input_shape=(batch_size, 100), output_shape=(batch_size, 500)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dense layer&lt;/td&gt;
      &lt;td&gt;neurons=500, input_shape=(batch_size, 500), output_shape=(batch_size, 500)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dense layer&lt;/td&gt;
      &lt;td&gt;neurons=784, input_shape=(batch_size, 500), output_shape=(batch_size, 784)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;reshape layer&lt;/td&gt;
      &lt;td&gt;input_shape=(batch_size, 784), output_shape=(batch_size, 28, 28)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;판별기 아키텍처 예&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;계층#&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;계층 이름&lt;/th&gt;
      &lt;th&gt;구성&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;flatten layer&lt;/td&gt;
      &lt;td&gt;input_shape=(batch_size, 28, 28), output_shape=(batch_size, 784)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dense layer&lt;/td&gt;
      &lt;td&gt;neurons=784, input_shape=(batch_size, 784), output_shape=(batch_size, 500)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dense layer&lt;/td&gt;
      &lt;td&gt;neurons=500, input_shape=(batch_size, 500), output_shape=(batch_size, 500)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dense layer&lt;/td&gt;
      &lt;td&gt;neurons=1, input_shape=(batch_size, 500), output_shape=(batch_size, 1)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;gan과-관련된-주요-개념&quot;&gt;GAN과 관련된 주요 개념&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;쿨백-라이블러 발산&lt;/strong&gt;&lt;/span&gt; 
쿨백-라이블러 발산(Kullback-Leibler divergence, KL 발산)은 상대 엔트로피(relative entropy)로도 알려져 있는데, &lt;span style=&quot;color:#AED6F1&quot;&gt;두가지 확률 분포 간의 유사도를 알아내는데 사용&lt;/span&gt;하는 방법이다. 하나의 확률분포 p(x)가 두번째 기대 확률 분포 q(x)와 어떻게 다른지 측정한다. p(x)와 q(x)가 같을때 KL 발산은 최소가 되고, KL 발산은 비대칭 특성이 있기 때문에 두 확률 분포 사이의 거리를 측정할때는 사용할 수 없다&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;옌센-섀넌 발산&lt;/strong&gt;&lt;/span&gt;
옌센-섀넌 발산(Jensen-Shannon divergence, JS 발산)은 정보 반경(information radius, IRaD)나 평균에 대한 총 발산(total divergence to the average)라고도 하며, 역시 &lt;span style=&quot;color:#AED6F1&quot;&gt;두가지 확률 분포 간의 유사도(similarity)를 알아내는데 사용&lt;/span&gt;하는 방법이다. KL 발산을 바탕으로 만들어 졌지만 JS 발산은 대칭적이며, 두 확률 분포 사이의 거리를 측정하는 데 사용할 수 있다&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;내시 균형&lt;/strong&gt;&lt;/span&gt;
내시 균형(Nash equilibrium)이란 게임 이론에서 특정 상태를 묘사할 때 쓰는 용어이다. 각 플레이어는 최선의 전략을 고르는 비협력 게임에서, 모든 플레이어들의 결정을 바탕으로 자신들만의최고 전략을 선택하게 되지만, 게임 도중에 이 지점에 도달하면 전략을 변화시킴으로써 얻을 수 있는 이익이 없게 된다.&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;목적 함수&lt;/strong&gt;&lt;/span&gt;
생성기와 판별기 모두 자체 목적 함수들이 훈련을 하는 동안 판별기는 총 출력을 최대화 하고, 생성기는 최소화하게 되어 GAN에 대한 최종 목적함수가 균형을 잡게 되고, 이때 모델이 수렴했다고 한다. 이 균형이 내시 균형이다.&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;인셉션 점수&lt;/strong&gt;&lt;/span&gt;
인셉션 점수(inception score, IS)는 GAN에서 가장 널리 사용하는 점수 알고리즘이다. 사전 훈련 인셉션 V3 신경망을 사용해 생성된 이미지와 진짜 이미지의 특징을 추출한다. 모델에서 생성된 영상 N개를 표본 추출한뒤 KL 발산 및 예상되는 인셉션을 계산하고 나온 결과값에 지수를 취하면 인셉션 점수를 알 수 있다. &lt;span style=&quot;color:#AED6F1&quot;&gt;인셉션 점수가 높다는 것은 모델 품질이 좋다는 말이다.&lt;/span&gt;&lt;br /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;&lt;strong&gt;프레셰 인셉션 거리&lt;/strong&gt;&lt;/span&gt;
프레세 인셉션 거리(Freshlet inception distance, FID)는 인셉션 점수의 다양한 단점을 극복하기 위한 방법이다. FID 점수는 인셉션 신경망을 사용하여 인셉션 신경망의 중간 계층에서 특징 지도를 추출한다. 그런 다음, 특징 지도의 분포를 학습하는 다변량 가우스 분포를 모델링한다. 수식을 계산하여 나온 &lt;span style=&quot;color:#AED6F1&quot;&gt;점수가 낮을 수록 모델이 더 좋아지고 더 다양한 이미지를 고품질로 생성&lt;/span&gt;할 수 있다. 인셉션 점수보다 잡음에 강하고 이미지의 다양성을 쉽게 측정할 수 있다.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;gan의-장단점&quot;&gt;GAN의 장단점&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;장점&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;GAN은 비지도학습 방식이다.&lt;/span&gt; 레이블 없이 데이터 훈련을 할 수 있다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;GAN은 데이터를 생성한다.&lt;/span&gt; 실제와 유사한 데이터를 늘릴 수 있다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;GAN은 데이터의 밀도 분포를 학습한다.&lt;/span&gt; 데이터의 내부 표현을 학습하여 다양한 문제에 응용할 수 있다&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;훈련된 판별기는 일종의 분류기이다.&lt;/span&gt; 판별기 신경망은 물체를 분류하는데 활용할 수 있다&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span style=&quot;color:yellow&quot;&gt;&lt;strong&gt;단점&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;최빈값 붕괴(mode collapse):&lt;/span&gt; 생성기 신경망이 표본을 다양하게 생성하지 못하는 문제이다&lt;/li&gt;
  &lt;li&gt;해결법: 다양한 최빈값을 지니게 여러 가지 모델(GAN)을 훈련, 다양한 데이터 표본으로 훈련&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;경사 소멸 (vanishing gradients):&lt;/span&gt; 경사도가 너무 작아져서 초기 계층의 가중치가 바뀌지 않아서 훈련이 중단되는 문제&lt;/li&gt;
  &lt;li&gt;해결법: ReLU, LeakyReLU 및 PReLU등의 활성함수를 활용하거나 배치 정규화(batch nomalization을 사용&lt;/li&gt;
  &lt;li&gt;&lt;span style=&quot;color:#F9E79F&quot;&gt;내부 공변량 변화(internal covariate shift):&lt;/span&gt; 입력 분포가 변경될 때 새로운 분포에 적응하기 위해 처리 과정이 느려져 전역 최솟값으로 수렴하는데 오랜 시간이 걸리는 문제
    &lt;ul&gt;
      &lt;li&gt;해결법: 배치 정규화 기법으로 해결&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;gan-훈련-시의-안정성-문제-해결하기&quot;&gt;GAN 훈련 시의 안정성 문제 해결하기&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.03498.pdf&quot;&gt;Improved Techniques for Training GANs&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.03498.pdf&quot;&gt;&lt;strong&gt;특징 정합&lt;/strong&gt;&lt;/a&gt;
특징 정합(feature matching)은 &lt;span style=&quot;color:#AED6F1&quot;&gt;목적함수가 수렴되는 것을 개선하&lt;/span&gt;기 위해 제안된 기술이다. 신경망은 판별기에게 이진 레이블을 제공하지 않게 하고 자체 신경망의 중간 계층에서 추출한 입력 데이터의 활성치나 특징 지도를 제공하여 진짜 데이터의 중요한 통계량을 학습하여 더 나은 결과를 얻을 수 있다. 하지만 수렴을 보장하지는 않는다&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.03498.pdf&quot;&gt;&lt;strong&gt;미니배치 판별&lt;/strong&gt;&lt;/a&gt;
&lt;span style=&quot;color:#AED6F1&quot;&gt;최빈값 붕괴(mode collapse)문제가 생겼을 때 사용하는 방법&lt;/span&gt;이다. 표본에 대한 특징 지도들을 추출하고 나서 이것들에 텐서를 곱한다. 그런 후에 각 행 사이의 L1 거리를 계산한다. 그리고 나서 특정 사례에 대한 모든 거리의 합계를 계산한다. 그런 다음에 접합하여 신경망의 다음 계층으로 공급한다&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.03498.pdf&quot;&gt;&lt;strong&gt;역사적 평균&lt;/strong&gt;&lt;/a&gt;
역사적 평균(historical averaging)이란 과거 파라미터의 평균을 취하여 이를 생성기 신경망 및 판별기 신경망의 각 비용 함수에 추가하는 접근 방식이다. 이를 통해 &lt;span style=&quot;color:#AED6F1&quot;&gt;훈련 안정성을 향상&lt;/span&gt;시킬 수 있다&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.03498.pdf&quot;&gt;&lt;strong&gt;단측 레이블 평활화&lt;/strong&gt;&lt;/a&gt;
단측 레이블 평활화(onesided label smoothing)는 판별기 신경망에 평활화된 레이블을 제공하여 0과 1 대신에 0.2, 0.7등의 소숫점을 가질 수 있게 하는 방법이다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1502.03167.pdf&quot;&gt;&lt;strong&gt;배치 정규화&lt;/strong&gt;&lt;/a&gt;
배치 정규화(batch normalization)는 평균 또는 단위 분산이 없도록 특징 벡터를 정규화하는 기술이다. 이것은 학습을 안정시키고 부족한 가중치 초기화 문제를 다루기 위해 사용된다. 배치 정규화는 신경망의 은닉계층에 적용하는 전처리 단계로서 &lt;span style=&quot;color:#AED6F1&quot;&gt;내부 공변량 변화를 줄이는 데 도움&lt;/span&gt;이 된다&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1607.08022.pdf&quot;&gt;&lt;strong&gt;사례 정규화&lt;/strong&gt;&lt;/a&gt;
해당 특징 지도의 정보만 활용하여 각 특징 지도를 정규화 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;그-밖의-다양한-gan&quot;&gt;그 밖의 다양한 GAN&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1511.06434.pdf&quot;&gt;&lt;strong&gt;DCGAN&lt;/strong&gt;&lt;/a&gt;: 최초로 GAN에 합성곱 신경망을 두었다&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1612.03242.pdf&quot;&gt;&lt;strong&gt;StackGAN&lt;/strong&gt;&lt;/a&gt;:  텍스트 대 이미지 합성을 탐구에 사용되는 GAN 알고리즘&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.10593.pdf&quot;&gt;&lt;strong&gt;CycleGAN&lt;/strong&gt;&lt;/a&gt;: 사진을 그림으로 변환하거나 그 반대로 변환하거나, 날씨등도 바꿀수 있는 GAN 알고리즘&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.07584.pdf&quot;&gt;&lt;strong&gt;3D-GAN&lt;/strong&gt;&lt;/a&gt;: 객체의 3D 모델에 대해 교육을 받으면 다른 객체의 새로운 3D 모델을 생성할 수 있다&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1702.01983.pdf&quot;&gt;&lt;strong&gt;Age-cGAN&lt;/strong&gt;&lt;/a&gt;: cGAN을 이용한 얼굴 노화에 대해 사용할 수 있다&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.07004.pdf&quot;&gt;&lt;strong&gt;pix2pix&lt;/strong&gt;&lt;/a&gt;: 건물 레이블을 사용해 건물 사진으로 변환하거나, 흑백 이미지를 컬러로 변환하는 등에 사용할 수 있다&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;출처: 실전! GAN 프로젝트, “위키북스”&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><category term="Deep Learning" /><category term="GAN" /><category term="generative adversarial networks" /></entry><entry><title type="html">우분투 도커 설치</title><link href="http://localhost:4000/ubuntu/ubuntu_docker_install/" rel="alternate" type="text/html" title="우분투 도커 설치" /><published>2019-11-27T00:00:00+09:00</published><updated>2019-11-27T00:00:00+09:00</updated><id>http://localhost:4000/ubuntu/ubuntu_docker_install</id><content type="html" xml:base="http://localhost:4000/ubuntu/ubuntu_docker_install/">&lt;h1 id=&quot;우분투-도커-설치이미지-폴더-변경-까지&quot;&gt;우분투 도커 설치(이미지 폴더 변경 까지)&lt;/h1&gt;

&lt;p&gt;우분투 환경에서 도커를 설치하는 방법을 정리해 보고자 한다. 
실행 환경: Ubuntu 18.04(LTS)
도커 버전: 19.03&lt;/p&gt;

&lt;p&gt;도커 설치 과정은  &lt;a href=&quot;https://docs.docker.com/install/linux/docker-ce/ubuntu/&quot;&gt;docs.docker.com&lt;/a&gt; 를 참고하여 순서대로 설명해 보겠다.&lt;/p&gt;

&lt;h2 id=&quot;1-uninstall-old-versions&quot;&gt;1. Uninstall old versions&lt;/h2&gt;
&lt;p&gt;기존에 도커가 설치되어 있다면 도커를 삭제하고 도커 폴더 역시 삭제한다.&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 도커 삭제
$ sudo apt-get remove docker docker-engine docker.io containerd runc

# 도커 폴더 삭제
$ sudo rm -rf /var/lib/docker
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;2-set-up-the-repository&quot;&gt;2. Set up the repository&lt;/h2&gt;
&lt;p&gt;도커 엔진을 설치하기 전에 새로운 기기에 도커 저장소를 설정하여 도커를 설치 및 업데이트 한다&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# apt 패키지 업데이트
$ sudo apt-get update

# HTTPS를 통해 저장소를 사용하기 쉬운 패키지 설치
$ sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg-agent \
    software-properties-common
		
# 도커의 공식 GPG key 추가하기(생략 가능)
$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
$ sudo apt-key fingerprint 0EBFCD88
    
pub   rsa4096 2017-02-22 [SCEA]
      9DC8 5822 9FC7 DD38 854A  E2D8 8D81 803C 0EBF CD88
uid           [ unknown] Docker Release (CE deb) &amp;lt;docker@docker.com&amp;gt;
sub   rsa4096 2017-02-22 [S]

# 안정적인 저장소 설정하기
$ sudo add-apt-repository \
   &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;3-install-docker-ce&quot;&gt;3. Install docker-CE&lt;/h2&gt;
&lt;p&gt;이제 도커를 설치해보자&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# apt 패키지 업데이트 수행
$ sudo apt-get update

# 최신 도커 설치
$ sudo apt-get install docker-ce docker-ce-cli containerd.io
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;31-install-nvidia-docker2option&quot;&gt;3.1 Install nvidia-docker2(Option)&lt;/h3&gt;
&lt;p&gt;추가적으로 nvidia-docker를 설치한다&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ sudo apt-get install nvidia-docker2
$ sudo pkill -SIGHUP dockerd
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;일반적으로 도커를 사용하는데 있어서 위의 절차까지 수행하면 크게 문제가 없다. &lt;br /&gt;
&lt;strong&gt;하지만&lt;/strong&gt; 도커의 이미지의 크기는 매우 크기 때문에 하드드라이브가 가득 차서 더이상 설치할 수 없게 된다. &lt;br /&gt;
그렇게 되지 않기 위하여 &lt;strong&gt;도커를 사용하면서 사용하지 않는 이미지나 컨테이너를 주기적으로 관리&lt;/strong&gt;해 주어야 하지만 대부분의 OS가 설치된 하드는 SSD이고 용량이 상대적으로 적기 때문에 &lt;strong&gt;도커 이미지 위치를 HDD로 변경&lt;/strong&gt;하여 사용한다&lt;/p&gt;

&lt;h2 id=&quot;4-docker-default-folder-change&quot;&gt;4. Docker default folder change&lt;/h2&gt;
&lt;p&gt;도커 폴더 변경은 &lt;a href=&quot;https://yookeun.github.io/docker/2018/10/29/docker-change/&quot;&gt;이곳&lt;/a&gt; 을 참조하였다. &lt;br /&gt; 2가지 방법이 나오는데 1번 방법(도커 실행 서비스에서 설정 변경)을 사용하였다&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/lib/systemd/system/docker.service&lt;/code&gt; 파일을 열고 아래 내용을 수정한다&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#ExecStart=/usr/bin/dockerd -H fd://
ExecStart=/usr/bin/dockerd -g /media/username/data/docker -H fd://
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/media/username/data/docker&lt;/code&gt; 이 경로를 자신의 폴더 경로로 변경한다&lt;/p&gt;

&lt;p&gt;도커를 중지하고 기본 도커 폴더의 내용을 이동&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 기본 폴더안의 내용을 옮기기 위해 docker를 중지
$ sudo systemctl stop docker
$ sudo systemctl daemon-reload

# 기존 도커 경로의 파일을 복사
$ sudo rsync -aqxP /var/lib/docker /media/username/data/docker
$ sudo rm -rf /var/lib/docker

# 도커 시작 및 확인
$ sudo systemctl start docker
$ ps -ef | grep docker
root      1442     1  0 11월27 ?      00:00:05 /usr/bin/dockerd -g /media/username/data/docker -H fd://
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;자신이 설정한 경로가 출력되는지 확인한다면 정상적으로 변경되었고 이제 마음것(?) 이미지를 생성할 수 있다!&lt;/p&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><category term="Ubuntu" /><category term="Docker" /></entry><entry><title type="html">네트워크 메인</title><link href="http://localhost:4000/networks/network_main/" rel="alternate" type="text/html" title="네트워크 메인" /><published>2019-11-26T00:00:00+09:00</published><updated>2019-11-26T00:00:00+09:00</updated><id>http://localhost:4000/networks/network_main</id><content type="html" xml:base="http://localhost:4000/networks/network_main/">&lt;h1 id=&quot;네트워크와-관련된-내용을-포스팅-해갈-예정입니다&quot;&gt;네트워크와 관련된 내용을 포스팅 해갈 예정입니다&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;/network_1/&quot; class=&quot;btn btn--success btn--large&quot;&gt;네트워크 1장&lt;/a&gt;&lt;/p&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><category term="Networks" /></entry><entry><title type="html">네트워크 1장</title><link href="http://localhost:4000/networks/network_1/" rel="alternate" type="text/html" title="네트워크 1장" /><published>2019-11-19T00:00:00+09:00</published><updated>2019-11-19T00:00:00+09:00</updated><id>http://localhost:4000/networks/network_1</id><content type="html" xml:base="http://localhost:4000/networks/network_1/">&lt;h2 id=&quot;lesson-1-정리&quot;&gt;Lesson 1 정리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;컴퓨터 간의 연결을 컴퓨터 네트워크라고 부른다&lt;/li&gt;
  &lt;li&gt;인터넷은 전 세계의 큰 네트워크부터 작은 네트워크까지 연결하는 거대한 네트워크다&lt;/li&gt;
  &lt;li&gt;패킷은 컴퓨터 간의 데이터를 주고받을 때 네트워크를 통해 흘러가는 작은 데이터 조각이다&lt;/li&gt;
  &lt;li&gt;큰 데이터는 작은 패킷으로 분할한다&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lesson-2-정리&quot;&gt;Lesson 2 정리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;컴퓨터는 0과 1밖에 이해하지 못한다&lt;/li&gt;
  &lt;li&gt;정보를 나타내는 최소 단위를 비트라고 하며, 비트 여덟 개를 1바이트라고 한다&lt;/li&gt;
  &lt;li&gt;숫자와 문자의 대응표를 문자코드라고 한다&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lesson-3-정리&quot;&gt;Lesson 3 정리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;건물 안이나 특정 지역을 범위로 하는 네트워크를 랜(Local Area Network, LAN)이라고 한다&lt;/li&gt;
  &lt;li&gt;인터넷 서비스 제공자(ISP)가 제공하는 서비스를 사용하여 구축한 네트워크를 왠(Wide Area Network, WAN)이라고 한다&lt;/li&gt;
  &lt;li&gt;랜은 왠보다 범위가 좁고 속도가 빠르며 오류가 발생할 확률이 낮다&lt;/li&gt;
  &lt;li&gt;왠은 랜보다 버무이가 넓고 속도가 느리며 오류가 발생할 확률이 높다&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lesson-4-정리&quot;&gt;Lesson 4 정리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;우선 인터넷 서비스 제공자와 인터넷회선을 결정하고 계약한다&lt;/li&gt;
  &lt;li&gt;인터넷 서비스 제공자와 인터넷 공유기로 접속한다&lt;/li&gt;
  &lt;li&gt;접속 방식에는 유선 랜 방식과 무선 랜 방식이 있다&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;lesson-5-정리&quot;&gt;Lesson 5 정리&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;DMZ는 외부에 공개하기 위한 네트워크다&lt;/li&gt;
  &lt;li&gt;외부에 공개하는 서버에는 주로 웹 서버, DNS 서버, 메일 서버가 있다&lt;/li&gt;
  &lt;li&gt;회사의 서버는 온프레미스나 클라우드로 운영되고 있다&lt;/li&gt;
  &lt;li&gt;각 서버나 컴퓨터는 스위치나 무선 랜 기능을 사용하여 사내 랜에 접속한다&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;용어-정리&quot;&gt;용어 정리&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;네트워크&lt;/strong&gt;: 컴퓨터를 두 대 이상 연결하여 서로 데이터를 전송할 수 있는 통신망&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;인터넷&lt;/strong&gt;: TCP/IP 프로토콜을 사용하는 세계 최대 규모의 네트워크다. 전 세계의 컴퓨터를 서로 연결하여 정보를 교환할 수 있도록 만든 하나의 거대한 컴퓨터 통신망이다&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;패킷&lt;/strong&gt;: 네트워크 통신을 할 때 사용되는 작게 분할된 데이터 조각으로 네트워크에서 전송하는 데이터의 기본 단위다&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;비트&lt;/strong&gt;: 정보의 최소 단위로 0 또는 1을 나타낸다&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;바이트&lt;/strong&gt;: 컴퓨터의 정보량 단위로 8비트를 1바이트라고 한다&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;랜&lt;/strong&gt;: 비교적 가까운 거리에 위치한 장치들을 서로 연결한 네트워크를 말한다. 집, 사무실, 학교 등의 건물과 같이 가까운 지역을 연결하는 네트워크다&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;왠&lt;/strong&gt;: 랜을 다시 하나로 묶은 거대한 네트워크다. 특정 도시, 국가, 대륙과 같이 매우 넓은 범위를 연결하는 네트워크를 말한다. 넓은 지역에 설치된 컴퓨터들 간의 정보와 자원을 공유하기에 적합하도록 설계한 컴퓨터 통신망이다&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;인터넷 서비스 제공자&lt;/strong&gt;: 인터넷에 접속하는 수단을 제공하는 주체다. 일반 사용자, 기업체, 기관, 단체 등이 인터넷에 접속하여 인터넷을 이용할 수 있도록 돕는 사업자다. 현재는 KT, U+, SK브로드밴드와 같은 ISP가 인터넷 서비스를 제공한다&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;서버&lt;/strong&gt;: 컴퓨터 네트워크에서 다른 컴퓨터에 서비스를 제공하기 위한 컴퓨터 또는 프로그램이다&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jaehoon Lee</name><email>machianb@naver.com</email></author><category term="Networks" /></entry></feed>
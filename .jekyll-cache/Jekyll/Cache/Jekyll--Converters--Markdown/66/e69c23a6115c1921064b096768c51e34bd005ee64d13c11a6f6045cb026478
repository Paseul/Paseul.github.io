I"<h1 id="신경망-아키텍처">신경망 아키텍처</h1>
<h2 id="다층-퍼셉트론multilayer-perceptron-mlp">다층 퍼셉트론(multilayer perceptron, MLP)</h2>
<p>신경망 아키텍처의 가장 기본적인 형태로서 신경 유닛은 층층이 배열되고 인접한 네트워크 층은 전체가 모두 연결된다
<img src="https://raw.githubusercontent.com/ledell/sldm4-h2o/master/mlp_network.png" alt="출처: https://github.com/rcassani/mlp-example" /></p>

<h2 id="오토인코더-신경망autoencoder">오토인코더 신경망(Autoencoder)</h2>
<p>목표값은 입력값과 동일하게 설정된다. 은닉층당 유닛 수가 점진적으로 증가하기 전에 특정 시점까지 점진적으로 감소하고, 최종 층의 차원은 입력 차원과 동일하다. 은닉층의 앞쪽 절반을 인코더(encoder) 뒤쪽 절반을 디코더(decoder)라고 한다.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Autoencoder_structure.png/350px-Autoencoder_structure.png" alt="출처: https://en.wikipedia.org/wiki/Autoencoder" /></p>
<blockquote>
  <p>출처: 딥러닝 전이학습, “위키북스”</p>
</blockquote>
:ET